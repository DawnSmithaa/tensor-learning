{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Temporal Matrix Factorization\n",
    "\n",
    "**Published**: October 8, 2019\n",
    "\n",
    "**Author**: Xinyu Chen [[**GitHub homepage**](https://github.com/xinychen)]\n",
    "\n",
    "**Download**: This Jupyter notebook is at our GitHub repository. If you want to evaluate the code, please download the notebook from the repository of [**tensor-learning**](https://github.com/xinychen/tensor-learning/blob/master/content/BTMF.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract\n",
    "\n",
    "Large-scale and multidimensional spatiotemporal data sets are becoming ubiquitous in many real-world applications such as monitoring traffic and air quality. Making predictions on these time series has become a critical challenge due to not only the large-scale and high-dimensional nature but also the considerable amount of missing data. In this work, we propose a Bayesian Temporal Matrix Factorization (BTMF) model for modeling multidimensional time series - and in particular spatiotemporal data - in the presence of missing data. By integrating low-rank matrix factorization and vector autoregressive (VAR) process into a single probabilistic graphical model, our model can effectively perform predictions without imputing those missing values. We develop efficient Gibbs sampling algorithms for model inference and test the proposed BTMF on several real-world spatiotemporal data sets for both missing data imputation and short-term rolling prediction tasks. This post is mainly about BTMF models and their **`Python`** implementation with an application of spatiotemporal data imputation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Motivation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Problem Description\n",
    "\n",
    "We assume a spatiotemporal setting for multidimensional time series data throughout this work. In general, modern spatiotemporal data sets collected from sensor networks can be organized as matrix time series. For example, we can denote by matrix $Y\\in\\mathbb{R}^{N\\times T}$ a multivariate time series collected from $N$ locations/sensors on $T$ time stamps, with each row $$\\boldsymbol{y}_{i}=\\left(y_{i,1},y_{i,2},...,y_{i,t-1},y_{i,t},y_{i,t+1},...,y_{i,T}\\right)$$\n",
    "corresponding to the time series collected at location $i$.\n",
    "\n",
    "As mentioned, making accurate predictions on incomplete time series is very challenging, while missing data problem is almost inevitable in real-world applications. Figure 1 illustrates the prediction problem for incomplete time series data. Here we use $(i,t)\\in\\Omega$ to index the observed entries in matrix $Y$.\n",
    "\n",
    "<img src=\"../images/graphical_matrix_time_series.png\" alt=\"drawing\" width=\"500\"/>\n",
    "\n",
    "> **Figure 1**: Illustration of multivariate time series and the prediction problem in the presence of missing values (green: observed data; white: missing data; red: prediction).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Model Description\n",
    "\n",
    "Given a partially observed spatiotemporal matrix $Y\\in\\mathbb{R}^{N \\times T}$, one can factorize it into a spatial factor matrix $W\\in\\mathbb{R}^{R \\times N}$ and a temporal factor matrix $X\\in\\mathbb{R}^{R \\times T}$ following general matrix factorization model:\n",
    "\\begin{equation}\n",
    "Y\\approx W^{\\top}X,\n",
    "\\label{btmf_equation1}\n",
    "\\end{equation}\n",
    "and element-wise, we have\n",
    "\\begin{equation}\n",
    "y_{it}\\approx \\boldsymbol{w}_{i}^\\top\\boldsymbol{x}_{t}, \\quad \\forall (i,t),\n",
    "\\label{btmf_equation2}\n",
    "\\end{equation}\n",
    "where vectors $\\boldsymbol{w}_{i}$ and $\\boldsymbol{x}_{t}$ refer to the $i$-th column of $W$ and the $t$-th column of $X$, respectively.\n",
    "\n",
    "The standard matrix factorization model is a good approach to deal with the missing data problem; however, it cannot capture the dependencies among different columns in $X$, which are critical in modeling time series data. To better characterize the temporal dependencies and impose temporal smoothness, a novel AR regularizer is introduced on $X$ in TRMF (i.e., Temporal Regularizer Matrix Factorization proposed by [Yu et al., 2016](https://www.cs.utexas.edu/~rofuyu/papers/tr-mf-nips.pdf)):\n",
    "\\begin{equation} \\label{equ:VAR}\n",
    "\\begin{aligned}\n",
    "    \\boldsymbol{x}_{t+1}&=\\sum\\nolimits_{k=1}^{d}A_{k}\\boldsymbol{x}_{t+1-h_k}+\\boldsymbol{\\epsilon}_t, \\\\\n",
    "    &=A^\\top \\boldsymbol{v}_{t+1}+\\boldsymbol{\\epsilon}_{t}, \\\\\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "where $\\mathcal{L}=\\left\\{h_1,\\ldots,h_k,\\ldots,h_d\\right\\}$ is a lag set ($d$ is the order of this AR model), each $A_k$ ($k\\in\\left\\{1,...,d\\right\\}$) is a $R\\times R$ coefficient matrix, and $\\boldsymbol{\\epsilon}_t$ is a zero mean Gaussian noise vector. For brevity, matrix $A\\in \\mathbb{R}^{(R d) \\times R}$ and vector $\\boldsymbol{v}_{t+1}\\in \\mathbb{R}^{(R d) \\times 1}$ are defined as\n",
    "\\begin{equation*}\n",
    "A=\\left[A_{1}, \\ldots, A_{d}\\right]^{\\top} ,\\quad \\boldsymbol{v}_{t+1}=\\left[\\begin{array}{c}{\\boldsymbol{x}_{t+1-h_1}} \\\\ {\\vdots} \\\\ {\\boldsymbol{x}_{t+1-h_d}}\\end{array}\\right] .\n",
    "\\end{equation*}\n",
    "\n",
    "<img src=\"../images/rolling_prediction.png\" alt=\"drawing\" width=\"400\"/>\n",
    "\n",
    "> **Figure 2**: A graphical illustration of the rolling prediction scheme using BTMF (with VAR process) (green: observed data; white: missing data; red: prediction).\n",
    "\n",
    "In [Yu et al., 2016](https://www.cs.utexas.edu/~rofuyu/papers/tr-mf-nips.pdf), to avoid overfitting and reduce the number of parameters, the coefficient matrix in TRMF is further assumed to be a diagonal $A_k=\\text{diag}(\\boldsymbol{\\theta}_{k})$. Therefore, they have\n",
    "\\begin{equation} \\label{equ:AR}\n",
    "\\boldsymbol{x}_{t+1}=\\boldsymbol{\\theta}_{1}\\circledast\\boldsymbol{x}_{t+1-h_1}+\\cdots+\\boldsymbol{\\theta}_{d}\\circledast\\boldsymbol{x}_{t+1-h_d}+\\boldsymbol{\\epsilon}_t,\n",
    "\\end{equation}\n",
    "where the symbol $\\circledast$ denotes the element-wise Hadamard product. However, unlike Equation (4), a vector autoregressive (VAR) model in Equation (3) is actually more powerful for capturing multivariate time series patterns. \n",
    "\n",
    "<img src=\"../images/rolling_prediction_strategy.png\" alt=\"drawing\" width=\"400\"/>\n",
    "\n",
    "> **Figure 3**: A graphical illustration of the rolling prediction scheme using BTMF (with AR process) (green: observed data; white: missing data; red: prediction).\n",
    "\n",
    "In the following, we first introduce a Bayesian temporal matrix factorization model with an autoregressive model given in Equation (4), and then discuss another model with a vector autoregressive (VAR) model shown in Equation (3).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Bayesian Temporal Matrix Factorization with Autoregressive Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Bayesian Temporal Matrix Factorization with Vector Autoregressive Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Model Specification\n",
    "\n",
    "Following the general Bayesian probabilistic matrix factorization models (e.g., BPMF proposed by [Salakhutdinov & Mnih, 2008](https://www.cs.toronto.edu/~amnih/papers/bpmf.pdf)), we assume that each observed entry in $Y$ follows a Gaussian distribution with precision $\\tau$:\n",
    "\\begin{equation}\n",
    "y_{i,t}\\sim\\mathcal{N}\\left(\\boldsymbol{w}_i^\\top\\boldsymbol{x}_t,\\tau^{-1}\\right),\\quad \\left(i,t\\right)\\in\\Omega.\n",
    "\\label{btmf_equation3}\n",
    "\\end{equation}\n",
    "\n",
    "On the spatial dimension, we use a simple Gaussian factor matrix without imposing any dependencies explicitly:\n",
    "\\begin{equation}\n",
    "\\boldsymbol{w}_i\\sim\\mathcal{N}\\left(\\boldsymbol{\\mu}_{w},\\Lambda_w^{-1}\\right),\n",
    "\\end{equation}\n",
    "and we place a conjugate Gaussian-Wishart prior on the mean vector and the precision matrix:\n",
    "\\begin{equation}\n",
    "\\boldsymbol{\\mu}_w | \\Lambda_w \\sim\\mathcal{N}\\left(\\boldsymbol{\\mu}_0,(\\beta_0\\Lambda_w)^{-1}\\right),\\Lambda_w\\sim\\mathcal{W}\\left(W_0,\\nu_0\\right),\n",
    "\\end{equation}\n",
    "where $\\boldsymbol{\\mu}_0\\in \\mathbb{R}^{R}$ is a mean vector, $\\mathcal{W}\\left(W_0,\\nu_0\\right)$ is a Wishart distribution with a $R\\times R$ scale matrix $W_0$ and $\\nu_0$ degrees of freedom.\n",
    "\n",
    "In modeling the temporal factor matrix $X$, we re-write the VAR process as:\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "\\boldsymbol{x}_{t}&\\sim\\begin{cases}\n",
    "\\mathcal{N}\\left(\\boldsymbol{0},I_R\\right),&\\text{if $t\\in\\left\\{1,2,...,h_d\\right\\}$}, \\\\\n",
    "\\mathcal{N}\\left(A^\\top \\boldsymbol{v}_{t},\\Sigma\\right),&\\text{otherwise},\\\\\n",
    "\\end{cases}\\\\\n",
    "\\end{aligned}\n",
    "\\label{btmf_equation5}\n",
    "\\end{equation}\n",
    "\n",
    "Since the mean vector is defined by VAR, we need to place the conjugate matrix normal inverse Wishart (MNIW) prior on the coefficient matrix $A$ and the covariance matrix $\\Sigma$ as follows,\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "A\\sim\\mathcal{MN}_{(Rd)\\times R}\\left(M_0,\\Psi_0,\\Sigma\\right),\\quad\n",
    "\\Sigma \\sim\\mathcal{IW}\\left(S_0,\\nu_0\\right), \\\\\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "where the probability density function for the $Rd$-by-$R$ random matrix $A$ has the form:\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "&p\\left(A\\mid M_0,\\Psi_0,\\Sigma\\right) \\\\\n",
    "=&\\left(2\\pi\\right)^{-R^2d/2}\\left|\\Psi_0\\right|^{-R/2}\\left|\\Sigma\\right|^{-Rd/2} \\\\\n",
    "&\\times \\exp\\left(-\\frac{1}{2}\\text{tr}\\left[\\Sigma^{-1}\\left(A-M_0\\right)^{\\top}\\Psi_{0}^{-1}\\left(A-M_0\\right)\\right]\\right), \\\\\n",
    "\\end{aligned}\n",
    "\\label{mnpdf}\n",
    "\\end{equation}\n",
    "where $\\Psi_0\\in\\mathbb{R}^{(Rd)\\times (Rd)}$ and $\\Sigma\\in\\mathbb{R}^{R\\times R}$ are played as covariance matrices.\n",
    "\n",
    "For the only remaining parameter $\\tau$, we place a Gamma prior  $\\tau\\sim\\text{Gamma}\\left(\\alpha,\\beta\\right)$ where $\\alpha$ and $\\beta$ are the shape and rate parameters, respectively. \n",
    "\n",
    "The above specifies the full generative process of BTMF, and we could also see the Bayesian graphical model shown in Figure 4. Several parameters are introduced to define the prior distributions for hyperparameters, including $\\boldsymbol{\\mu}_{0}$, $W_0$, $\\nu_0$, $\\beta_0$, $\\alpha$, $\\beta$, $M_0$, $\\Psi_0$, and $S_0$. These parameters need to provided in advance when training the model. However, it should be noted that the specification of these parameters has little impact on the final results, as the training data will play a much more important role in defining the posteriors of the hyperparameters.\n",
    "\n",
    "<img src=\"../images/btmf_net.png\" alt=\"drawing\" width=\"450\"/>\n",
    "\n",
    "> **Figure 4**: An overview graphical model of BTMF (time lag set: $\\left\\{1,2,...,d\\right\\}$). The shaded nodes ($y_{i,t}$) are the observed data in $\\Omega$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Model Inference\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the complex structure of BTMF, it is intractable to write down the posterior distribution. Here we rely on the MCMC technique for Bayesian learning. In detail, we introduce a Gibbs sampling algorithm by deriving the full conditional distributions for all parameters and hyperparameters. Thanks to the use of conjugate priors in Figure 4, we can actually write down all the conditional distributions analytically. Below we summarize the Gibbs sampling procedure.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Sampling Factor Matrix $W$ and Its Hyperparameters\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> For programming convenience, we use $W\\in\\mathbb{R}^{N\\times R}$ to replace $W\\in\\mathbb{R}^{R\\times N}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import inv as inv\n",
    "from numpy.random import multivariate_normal as mvnrnd\n",
    "from scipy.stats import wishart\n",
    "\n",
    "def cov_mat(mat):\n",
    "    dim1, dim2 = mat.shape\n",
    "    new_mat = np.zeros((dim2, dim2))\n",
    "    mat_bar = np.mean(mat, axis = 0)\n",
    "    for i in range(dim1):\n",
    "        new_mat += np.einsum('i, j -> ij', mat[i, :] - mat_bar, mat[i, :] - mat_bar)\n",
    "    return new_mat\n",
    "\n",
    "def sample_factor_w(sparse_mat, binary_mat, W, X, tau):\n",
    "    \"\"\"Sampling N-by-R factor matrix W and its hyperparameters (mu_w, Lambda_w).\"\"\"\n",
    "    dim1, rank = W.shape\n",
    "    beta0 = 1\n",
    "    W_bar = np.mean(W, axis = 0)\n",
    "    var_mu_hyper = (dim1 * W_bar)/(dim1 + beta0)\n",
    "    var_W_hyper = inv(np.eye(rank) + cov_mat(W) + dim1 * beta0/(dim1 + beta0) * np.outer(W_bar, W_bar))\n",
    "    var_Lambda_hyper = wishart(df = dim1 + rank, scale = var_W_hyper, seed = None).rvs()\n",
    "    var_mu_hyper = mvnrnd(var_mu_hyper, inv((dim1 + beta0) * var_Lambda_hyper))\n",
    "    for i in range(dim1):\n",
    "        pos0 = np.where(sparse_mat[i, :] != 0)\n",
    "        Xt = X[pos0[0], :]\n",
    "        var_mu = tau * np.matmul(Xt.T, sparse_mat[i, pos0[0]]) + np.matmul(var_Lambda_hyper, var_mu_hyper)\n",
    "        inv_var_Lambda = inv(tau * np.matmul(Xt.T, Xt) + var_Lambda_hyper)\n",
    "        W[i, :] = mvnrnd(np.matmul(inv_var_Lambda, var_mu), inv_var_Lambda)\n",
    "    return W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Sampling VAR Coefficients $A$ and Its Hyperparameters\n",
    "\n",
    "**Foundations of VAR**\n",
    "\n",
    "Vector autoregression (VAR) is a multivariate extension of autoregression (AR). Formally, VAR for $R$-dimensional vectors $\\boldsymbol{x}_{t}$ can be written as follows,\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "\\boldsymbol{x}_{t}&=A_{1} \\boldsymbol{x}_{t-h_1}+\\cdots+A_{d} \\boldsymbol{x}_{t-h_d}+\\boldsymbol{\\epsilon}_{t}, \\\\\n",
    "&= A^\\top \\boldsymbol{v}_{t}+\\boldsymbol{\\epsilon}_{t},~t=h_d+1, \\ldots, T, \\\\\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "where\n",
    "\\begin{equation}\n",
    "A=\\left[A_{1}, \\ldots, A_{d}\\right]^{\\top} \\in \\mathbb{R}^{(R d) \\times R},\\quad \\boldsymbol{v}_{t}=\\left[\\begin{array}{c}{\\boldsymbol{x}_{t-h_1}} \\\\ {\\vdots} \\\\ {\\boldsymbol{x}_{t-h_d}}\\end{array}\\right] \\in \\mathbb{R}^{(R d) \\times 1}.\n",
    "\\end{equation}\n",
    "\n",
    "In the following, if we define\n",
    "\\begin{equation}\n",
    "Z=\\left[\\begin{array}{c}{\\boldsymbol{x}_{h_d+1}^{\\top}} \\\\ {\\vdots} \\\\ {\\boldsymbol{x}_{T}^{\\top}}\\end{array}\\right] \\in \\mathbb{R}^{(T-h_d) \\times R},\\quad Q=\\left[\\begin{array}{c}{\\boldsymbol{v}_{h_d+1}^{\\top}} \\\\ {\\vdots} \\\\ {\\boldsymbol{v}_{T}^{\\top}}\\end{array}\\right] \\in \\mathbb{R}^{(T-h_d) \\times(R d)},\n",
    "\\end{equation}\n",
    "then, we could write the above mentioned VAR as\n",
    "\\begin{equation}\n",
    "\\underbrace{Z}_{(T-h_d)\\times R}\\approx \\underbrace{Q}_{(T-h_d)\\times (Rd)}\\times \\underbrace{A}_{(Rd)\\times R}.\n",
    "\\end{equation}\n",
    "\n",
    "> To include temporal factors $\\boldsymbol{x}_{t},t=1,...,h_d$, we also define $$Z_0=\\left[\\begin{array}{c}{\\boldsymbol{x}_{1}^{\\top}} \\\\ {\\vdots} \\\\ {\\boldsymbol{x}_{h_d}^{\\top}}\\end{array}\\right] \\in \\mathbb{R}^{h_d \\times R}.$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Build a Bayesian VAR on temporal factors $\\boldsymbol{x}_{t}$**\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "\\boldsymbol{x}_{t}&\\sim\\begin{cases}\\mathcal{N}\\left(A^\\top \\boldsymbol{v}_{t},\\Sigma\\right),~\\text{if $t\\in\\left\\{h_d+1,...,T\\right\\}$},\\\\{\\mathcal{N}\\left(\\boldsymbol{0},I_R\\right),~\\text{otherwise}}.\\end{cases}\\\\\n",
    "A&\\sim\\mathcal{MN}_{(Rd)\\times R}\\left(M_0,\\Psi_0,\\Sigma\\right), \\\\\n",
    "\\Sigma &\\sim\\mathcal{IW}\\left(S_0,\\nu_0\\right), \\\\\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "where\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "&\\mathcal{M N}_{(R d) \\times R}\\left(A | M_{0}, \\Psi_{0}, \\Sigma\\right)\\\\\n",
    "\\propto|&\\Sigma|^{-R d / 2} \\exp \\left(-\\frac{1}{2} \\operatorname{tr}\\left[\\Sigma^{-1}\\left(A-M_{0}\\right)^{\\top} \\Psi_{0}^{-1}\\left(A-M_{0}\\right)\\right]\\right), \\\\\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "and\n",
    "\\begin{equation}\n",
    "\\mathcal{I} \\mathcal{W}\\left(\\Sigma | S_{0}, \\nu_{0}\\right) \\propto|\\Sigma|^{-\\left(\\nu_{0}+R+1\\right) / 2} \\exp \\left(-\\frac{1}{2} \\operatorname{tr}\\left(\\Sigma^{-1}S_{0}\\right)\\right).\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Likelihood from temporal factors $\\boldsymbol{x}_{t}$**\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "&\\mathcal{L}\\left(X\\mid A,\\Sigma\\right) \\\\\n",
    "\\propto &\\prod_{t=1}^{h_d}p\\left(\\boldsymbol{x}_{t}\\mid \\Sigma\\right)\\times \\prod_{t=h_d+1}^{T}p\\left(\\boldsymbol{x}_{t}\\mid A,\\Sigma\\right) \\\\\n",
    "\\propto &\\left|\\Sigma\\right|^{-T/2}\\exp\\left\\{-\\frac{1}{2}\\sum_{t=h_d+1}^{T}\\left(\\boldsymbol{x}_{t}-A^\\top \\boldsymbol{v}_{t}\\right)^\\top\\Sigma^{-1}\\left(\\boldsymbol{x}_{t}-A^\\top \\boldsymbol{v}_{t}\\right)\\right\\} \\\\\n",
    "\\propto &\\left|\\Sigma\\right|^{-T/2}\\exp\\left\\{-\\frac{1}{2}\\text{tr}\\left[\\Sigma^{-1}\\left(Z_0^\\top Z_0+\\left(Z-QA\\right)^\\top \\left(Z-QA\\right)\\right)\\right]\\right\\}\n",
    "\\end{aligned}\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Posterior distribution**\n",
    "\n",
    "Consider\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "&\\left(A-M_{0}\\right)^{\\top} \\Psi_{0}^{-1}\\left(A-M_{0}\\right)+S_0+Z_0^\\top Z_0+\\left(Z-QA\\right)^\\top \\left(Z-QA\\right) \\\\\n",
    "=&A^\\top\\left(\\Psi_0^{-1}+Q^\\top Q\\right)A-A^\\top\\left(\\Psi_0^{-1}M_0+Q^\\top Z\\right) \\\\\n",
    "&-\\left(\\Psi_0^{-1}M_0+Q^\\top Z\\right)^\\top A \\\\\n",
    "&+\\left(\\Psi_0^{-1}M_0+Q^\\top Z\\right)^\\top\\left(\\Psi_0^{-1}+Q^\\top Q\\right)\\left(\\Psi_0^{-1}M_0+Q^\\top Z\\right) \\\\\n",
    "&-\\left(\\Psi_0^{-1}M_0+Q^\\top Z\\right)^\\top\\left(\\Psi_0^{-1}+Q^\\top Q\\right)\\left(\\Psi_0^{-1}M_0+Q^\\top Z\\right) \\\\\n",
    "&+M_0^\\top\\Psi_0^{-1}M_0+S_0+Z_0^\\top Z_0+Z^\\top Z \\\\\n",
    "=&\\left(A-M^{*}\\right)^\\top\\left(\\Psi^{*}\\right)^{-1}\\left(A-M^{*}\\right)+S^{*}, \\\\\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "which is in the form of $\\mathcal{MN}\\left(\\cdot\\right)$ and $\\mathcal{IW}\\left(\\cdot\\right)$.\n",
    "\n",
    "The $Rd$-by-$R$ matrix $A$ has a matrix normal distribution, and $R$-by-$R$ covariance matrix $\\Sigma$ has an inverse Wishart distribution, that is,\n",
    "\\begin{equation}\n",
    "A \\sim \\mathcal{M N}_{(R d) \\times R}\\left(M^{*}, \\Psi^{*}, \\Sigma\\right), \\quad \\Sigma \\sim \\mathcal{I} \\mathcal{W}\\left(S^{*}, \\nu^{*}\\right),\n",
    "\\end{equation}\n",
    "with\n",
    "\\begin{equation}\n",
    "\\begin{cases}\n",
    "{\\Psi^{*}=\\left(\\Psi_{0}^{-1}+Q^{\\top} Q\\right)^{-1}}, \\\\ {M^{*}=\\Psi^{*}\\left(\\Psi_{0}^{-1} M_{0}+Q^{\\top} Z\\right)}, \\\\ {S^{*}=S_{0}+Z^\\top Z+M_0^\\top\\Psi_0^{-1}M_0-\\left(M^{*}\\right)^\\top\\left(\\Psi^{*}\\right)^{-1}M^{*}}, \\\\ \n",
    "{\\nu^{*}=\\nu_{0}+T-h_d}.\n",
    "\\end{cases}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import invwishart\n",
    "\n",
    "def mat2ten(mat, tensor_size, mode):\n",
    "    index = list()\n",
    "    index.append(mode)\n",
    "    for i in range(tensor_size.shape[0]):\n",
    "        if i != mode:\n",
    "            index.append(i)\n",
    "    return np.moveaxis(np.reshape(mat, list(tensor_size[index]), order = 'F'), 0, mode)\n",
    "\n",
    "def mnrnd(M, U, V):\n",
    "    \"\"\"\n",
    "    Generate matrix normal distributed random matrix.\n",
    "    M is a m-by-n matrix, U is a m-by-m matrix, and V is a n-by-n matrix.\n",
    "    \"\"\"\n",
    "    dim1, dim2 = M.shape\n",
    "    X0 = np.random.rand(dim1, dim2)\n",
    "    P = np.linalg.cholesky(U)\n",
    "    Q = np.linalg.cholesky(V)\n",
    "    return M + np.matmul(np.matmul(P, X0), Q.T)\n",
    "\n",
    "def sample_var_coefficient(X, time_lags):\n",
    "    dim2, rank = X.shape\n",
    "    d = time_lags.shape[0]\n",
    "    Z_mat = X[np.max(time_lags) : dim2, :]\n",
    "    Q_mat = np.zeros((dim2 - np.max(time_lags), rank * d))\n",
    "    for t in range(np.max(time_lags), dim2):\n",
    "        Q_mat[t - np.max(time_lags), :] = X[t - time_lags, :].reshape([rank * d])\n",
    "    var_Psi = inv(np.eye(rank * d) + np.matmul(Q_mat.T, Q_mat))\n",
    "    var_M = np.matmul(var_Psi, np.matmul(Q_mat.T, Z_mat))\n",
    "    var_S = (np.eye(rank) + np.matmul(Z_mat.T, Z_mat) - np.matmul(np.matmul(var_M.T, inv(var_Psi)), var_M))\n",
    "    Sigma = invwishart(df = rank + dim2 - np.max(time_lags), scale = var_S, seed = None).rvs()\n",
    "    return mat2ten(mnrnd(var_M, var_Psi, Sigma).T, np.array([rank, rank, d]), 0), Sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) Sampling Factor Matrix $X$\n",
    "\n",
    "**Posterior distribution**\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "y_{it}&\\sim\\mathcal{N}\\left(\\boldsymbol{w}_{i}^\\top\\boldsymbol{x}_{t},\\tau^{-1}\\right),~\\left(i,t\\right)\\in\\Omega, \\\\\n",
    "\\boldsymbol{x}_{t}&\\sim\\begin{cases}\\mathcal{N}\\left(\\sum_{k=1}^{d}A_{k} \\boldsymbol{x}_{t-h_k},\\Sigma\\right),~\\text{if $t\\in\\left\\{h_d+1,...,T\\right\\}$},\\\\{\\mathcal{N}\\left(\\boldsymbol{0},I\\right),~\\text{otherwise}}.\\end{cases}\\\\\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "\n",
    "If $t\\in\\left\\{1,...,h_d\\right\\}$, parameters of the posterior distribution $\\mathcal{N}\\left(\\boldsymbol{x}_{t}\\mid \\boldsymbol{\\mu}_{t}^{*},\\Sigma_{t}^{*}\\right)$ are\n",
    "\\footnotesize{\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "\\Sigma_{t}^{*}&=\\left(\\sum_{k=1, h_{d}<t+h_{k} \\leq T}^{d} {A}_{k}^{\\top} \\Sigma^{-1} A_{k}+\\tau\\sum_{i:(i,t)\\in\\Omega}\\boldsymbol{w}_{i}\\boldsymbol{w}_{i}^\\top+I\\right)^{-1}, \\\\\n",
    "\\boldsymbol{\\mu}_{t}^{*}&=\\Sigma_{t}^{*}\\left(\\sum_{k=1, h_{d}<t+h_{k} \\leq T}^{d} A_{k}^{\\top} \\Sigma^{-1} \\boldsymbol{\\psi}_{t+h_{k}}+\\tau\\sum_{i:(i,t)\\in\\Omega}\\boldsymbol{w}_{i}y_{it}\\right). \\\\\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "\n",
    "If $t\\in\\left\\{h_d+1,...,T\\right\\}$, then parameters of the posterior distribution $\\mathcal{N}\\left(\\boldsymbol{x}_{t}\\mid \\boldsymbol{\\mu}_{t}^{*},\\Sigma_{t}^{*}\\right)$ are\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "\\Sigma_{t}^{*}&=\\left(\\sum_{k=1, h_{d}<t+h_{k} \\leq T}^{d} {A}_{k}^{\\top} \\Sigma^{-1} A_{k}+\\tau\\sum_{i:(i,t)\\in\\Omega}\\boldsymbol{w}_{i}\\boldsymbol{w}_{i}^\\top+\\Sigma^{-1}\\right)^{-1}, \\\\\n",
    "\\boldsymbol{\\mu}_{t}^{*}&=\\Sigma_{t}^{*}\\left(\\sum_{k=1, h_{d}<t+h_{k} \\leq T}^{d} A_{k}^{\\top} \\Sigma^{-1} \\boldsymbol{\\psi}_{t+h_{k}}+\\tau\\sum_{i:(i,t)\\in\\Omega}\\boldsymbol{w}_{i}y_{it}+\\Sigma^{-1}\\sum_{k=1}^{d}A_{k}\\boldsymbol{x}_{t-h_k}\\right), \\\\\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "where\n",
    "$$\\boldsymbol{\\psi}_{t+h_k}=\\boldsymbol{x}_{t+h_k}-\\sum_{l=1,l\\neq k}^{d}A_{l}\\boldsymbol{x}_{t+h_k-h_l}.$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ten2mat(tensor, mode):\n",
    "    return np.reshape(np.moveaxis(tensor, mode, 0), (tensor.shape[mode], -1), order = 'F')\n",
    "\n",
    "def sample_factor_x(sparse_mat, binary_mat, time_lags, W, X, tau, A, Lambda_x):\n",
    "    dim2, rank = X.shape\n",
    "    d = time_lags.shape[0]\n",
    "    A_mat = ten2mat(A, 0)\n",
    "    for t in range(dim2):\n",
    "        pos0 = np.where(sparse_mat[:, t] != 0)\n",
    "        Wt = W[pos0[0], :]\n",
    "        Mt = np.zeros((rank, rank))\n",
    "        Nt = np.zeros(rank)\n",
    "        if t >= np.max(time_lags):\n",
    "            Qt = np.matmul(Lambda_x, np.matmul(A_mat, X[t - time_lags, :].reshape([rank * d])))\n",
    "        if t >= np.max(time_lags) and t < dim2 - np.max(time_lags):\n",
    "            index = list(range(0, d))\n",
    "        elif t >= dim2 - np.max(time_lags) and t < dim2 - np.min(time_lags):\n",
    "            index = list(np.where(t + time_lags < dim2))[0]\n",
    "        elif t < np.max(time_lags):\n",
    "            Qt = np.zeros(rank)\n",
    "            index = list(np.where(t + time_lags >= np.max(time_lags)))[0]\n",
    "        if t < dim2 - np.min(time_lags):\n",
    "            for k in index:\n",
    "                Ak = A[:, :, k]\n",
    "                Mt += np.matmul(np.matmul(Ak.T, Lambda_x), Ak)\n",
    "                A0 = A.copy()\n",
    "                A0[:, :, k] = 0\n",
    "                var5 = (X[t + time_lags[k], :] \n",
    "                        - np.matmul(ten2mat(A0, 0), X[t + time_lags[k] - time_lags, :].reshape([rank * d])))\n",
    "                Nt += np.matmul(np.matmul(Ak.T, Lambda_x), var5)\n",
    "        var_mu = tau * np.matmul(Wt.T, sparse_mat[pos0[0], t]) + Nt + Qt\n",
    "        if t < np.max(time_lags):\n",
    "            inv_var_Lambda = inv(tau * np.matmul(Wt.T, Wt) + Mt + np.eye(rank))\n",
    "        else:\n",
    "            inv_var_Lambda = inv(tau * np.matmul(Wt.T, Wt) + Mt + Lambda_x)\n",
    "        X[t, :] = mvnrnd(np.matmul(inv_var_Lambda, var_mu), inv_var_Lambda)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) Sampling Precision $\\tau$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_precision_tau(sparse_mat, mat_hat, position):\n",
    "    var_alpha = 1e-6 + 0.5 * sparse_mat[position].shape[0]\n",
    "    var_beta = 1e-6 + 0.5 * np.sum((sparse_mat - mat_hat)[position] ** 2)\n",
    "    return np.random.gamma(var_alpha, 1/var_beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5) BTMF Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BTMF(dense_mat, sparse_mat, init, rank, time_lags, maxiter1, maxiter2):\n",
    "    \"\"\"Bayesian Temporal Matrix Factorization, BTMF.\"\"\"\n",
    "    \n",
    "    W = init[\"W\"]\n",
    "    X = init[\"X\"]\n",
    "    dim1, dim2 = sparse_mat.shape\n",
    "    d = time_lags.shape[0]\n",
    "    pos = np.where((dense_mat != 0) & (sparse_mat == 0))\n",
    "    position = np.where(sparse_mat != 0)\n",
    "    binary_mat = np.zeros((dim1, dim2))\n",
    "    binary_mat[position] = 1\n",
    "    tau = 1\n",
    "    mat_hat_plus = np.zeros((dim1, dim2))\n",
    "    for it in range(maxiter1):\n",
    "        W = sample_factor_w(sparse_mat, binary_mat, W, X, tau)\n",
    "        A, Sigma = sample_var_coefficient(X, time_lags)\n",
    "        X = sample_factor_x(sparse_mat, binary_mat, time_lags, W, X, tau, A, inv(Sigma))\n",
    "        mat_hat = np.matmul(W, X.T)\n",
    "        tau = sample_precision_tau(sparse_mat, mat_hat, position)\n",
    "        rmse = np.sqrt(np.sum((dense_mat[pos] - mat_hat[pos]) ** 2)/dense_mat[pos].shape[0])\n",
    "        if (it + 1) % 1 == 0 and it < maxiter1 - maxiter2:\n",
    "            print('Iteration: {}'.format(it + 1))\n",
    "            print('RMSE: {:.6}'.format(rmse))\n",
    "            print()\n",
    "        if it + 1 > maxiter1 - maxiter2:\n",
    "            mat_hat_plus += mat_hat\n",
    "    mat_hat = mat_hat_plus/maxiter2\n",
    "    final_mape = np.sum(np.abs(dense_mat[pos] - mat_hat[pos])/dense_mat[pos])/dense_mat[pos].shape[0]\n",
    "    final_rmse = np.sqrt(np.sum((dense_mat[pos] - mat_hat[pos]) ** 2)/dense_mat[pos].shape[0])\n",
    "    print('Imputation MAPE: {:.6}'.format(final_mape))\n",
    "    print('Imputation RMSE: {:.6}'.format(final_rmse))\n",
    "    print()\n",
    "    return mat_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 Toy Example: Spatiotemporal Data Imputation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "tensor = scipy.io.loadmat('../datasets/Guangzhou-data-set/tensor.mat')\n",
    "tensor = tensor['tensor']\n",
    "random_matrix = scipy.io.loadmat('../datasets/Guangzhou-data-set/random_matrix.mat')\n",
    "random_matrix = random_matrix['random_matrix']\n",
    "random_tensor = scipy.io.loadmat('../datasets/Guangzhou-data-set/random_tensor.mat')\n",
    "random_tensor = random_tensor['random_tensor']\n",
    "\n",
    "dense_mat = tensor.reshape([tensor.shape[0], tensor.shape[1] * tensor.shape[2]])\n",
    "missing_rate = 0.4\n",
    "\n",
    "# =============================================================================\n",
    "### Random missing (RM) scenario\n",
    "### Set the RM scenario by:\n",
    "binary_mat = (np.round(random_tensor + 0.5 - missing_rate)\n",
    "              .reshape([random_tensor.shape[0], random_tensor.shape[1] * random_tensor.shape[2]]))\n",
    "# =============================================================================\n",
    "\n",
    "sparse_mat = np.multiply(dense_mat, binary_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputation MAPE: 0.0995009\n",
      "Imputation RMSE: 4.14718\n",
      "\n",
      "Running time: 324 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "dim1, dim2 = sparse_mat.shape\n",
    "rank = 10\n",
    "time_lags = np.array([1, 2, 144])\n",
    "init = {\"W\": 0.1 * np.random.rand(dim1, rank), \"X\": 0.1 * np.random.rand(dim2, rank)}\n",
    "maxiter1 = 100\n",
    "maxiter2 = 100\n",
    "BTMF(dense_mat, sparse_mat, init, rank, time_lags, maxiter1, maxiter2)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dense_mat = pd.read_csv('../datasets/Seattle-data-set/mat.csv', index_col = 0)\n",
    "RM_mat = pd.read_csv('../datasets/Seattle-data-set/RM_mat.csv', index_col = 0)\n",
    "dense_mat = dense_mat.values\n",
    "RM_mat = RM_mat.values\n",
    "\n",
    "missing_rate = 0.4\n",
    "\n",
    "# =============================================================================\n",
    "### Random missing (RM) scenario\n",
    "### Set the RM scenario by:\n",
    "binary_mat = np.round(RM_mat + 0.5 - missing_rate)\n",
    "# =============================================================================\n",
    "\n",
    "sparse_mat = np.multiply(dense_mat, binary_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1\n",
      "RMSE: 8.54652\n",
      "\n",
      "Iteration: 2\n",
      "RMSE: 8.25793\n",
      "\n",
      "Iteration: 3\n",
      "RMSE: 6.82373\n",
      "\n",
      "Iteration: 4\n",
      "RMSE: 6.29088\n",
      "\n",
      "Iteration: 5\n",
      "RMSE: 6.26116\n",
      "\n",
      "Iteration: 6\n",
      "RMSE: 6.11663\n",
      "\n",
      "Iteration: 7\n",
      "RMSE: 5.9606\n",
      "\n",
      "Iteration: 8\n",
      "RMSE: 5.94366\n",
      "\n",
      "Iteration: 9\n",
      "RMSE: 5.90364\n",
      "\n",
      "Iteration: 10\n",
      "RMSE: 5.79692\n",
      "\n",
      "Iteration: 11\n",
      "RMSE: 5.77708\n",
      "\n",
      "Iteration: 12\n",
      "RMSE: 5.75393\n",
      "\n",
      "Iteration: 13\n",
      "RMSE: 5.64862\n",
      "\n",
      "Iteration: 14\n",
      "RMSE: 5.54195\n",
      "\n",
      "Iteration: 15\n",
      "RMSE: 5.47609\n",
      "\n",
      "Iteration: 16\n",
      "RMSE: 5.42693\n",
      "\n",
      "Iteration: 17\n",
      "RMSE: 5.42135\n",
      "\n",
      "Iteration: 18\n",
      "RMSE: 5.41639\n",
      "\n",
      "Iteration: 19\n",
      "RMSE: 5.4097\n",
      "\n",
      "Iteration: 20\n",
      "RMSE: 5.39612\n",
      "\n",
      "Iteration: 21\n",
      "RMSE: 5.3333\n",
      "\n",
      "Iteration: 22\n",
      "RMSE: 5.23819\n",
      "\n",
      "Iteration: 23\n",
      "RMSE: 5.1996\n",
      "\n",
      "Iteration: 24\n",
      "RMSE: 5.18862\n",
      "\n",
      "Iteration: 25\n",
      "RMSE: 5.1844\n",
      "\n",
      "Iteration: 26\n",
      "RMSE: 5.17956\n",
      "\n",
      "Iteration: 27\n",
      "RMSE: 5.17783\n",
      "\n",
      "Iteration: 28\n",
      "RMSE: 5.17189\n",
      "\n",
      "Iteration: 29\n",
      "RMSE: 5.15882\n",
      "\n",
      "Iteration: 30\n",
      "RMSE: 5.13258\n",
      "\n",
      "Iteration: 31\n",
      "RMSE: 5.1249\n",
      "\n",
      "Iteration: 32\n",
      "RMSE: 5.1116\n",
      "\n",
      "Iteration: 33\n",
      "RMSE: 5.07737\n",
      "\n",
      "Iteration: 34\n",
      "RMSE: 5.05637\n",
      "\n",
      "Iteration: 35\n",
      "RMSE: 5.04501\n",
      "\n",
      "Iteration: 36\n",
      "RMSE: 5.02225\n",
      "\n",
      "Iteration: 37\n",
      "RMSE: 5.00356\n",
      "\n",
      "Iteration: 38\n",
      "RMSE: 4.99315\n",
      "\n",
      "Iteration: 39\n",
      "RMSE: 4.98749\n",
      "\n",
      "Iteration: 40\n",
      "RMSE: 4.97924\n",
      "\n",
      "Iteration: 41\n",
      "RMSE: 4.95565\n",
      "\n",
      "Iteration: 42\n",
      "RMSE: 4.93692\n",
      "\n",
      "Iteration: 43\n",
      "RMSE: 4.92391\n",
      "\n",
      "Iteration: 44\n",
      "RMSE: 4.90078\n",
      "\n",
      "Iteration: 45\n",
      "RMSE: 4.89054\n",
      "\n",
      "Iteration: 46\n",
      "RMSE: 4.88453\n",
      "\n",
      "Iteration: 47\n",
      "RMSE: 4.87351\n",
      "\n",
      "Iteration: 48\n",
      "RMSE: 4.8561\n",
      "\n",
      "Iteration: 49\n",
      "RMSE: 4.84395\n",
      "\n",
      "Iteration: 50\n",
      "RMSE: 4.83496\n",
      "\n",
      "Iteration: 51\n",
      "RMSE: 4.81409\n",
      "\n",
      "Iteration: 52\n",
      "RMSE: 4.80029\n",
      "\n",
      "Iteration: 53\n",
      "RMSE: 4.79179\n",
      "\n",
      "Iteration: 54\n",
      "RMSE: 4.78074\n",
      "\n",
      "Iteration: 55\n",
      "RMSE: 4.76313\n",
      "\n",
      "Iteration: 56\n",
      "RMSE: 4.75216\n",
      "\n",
      "Iteration: 57\n",
      "RMSE: 4.74665\n",
      "\n",
      "Iteration: 58\n",
      "RMSE: 4.73792\n",
      "\n",
      "Iteration: 59\n",
      "RMSE: 4.72666\n",
      "\n",
      "Iteration: 60\n",
      "RMSE: 4.71382\n",
      "\n",
      "Iteration: 61\n",
      "RMSE: 4.70261\n",
      "\n",
      "Iteration: 62\n",
      "RMSE: 4.69827\n",
      "\n",
      "Iteration: 63\n",
      "RMSE: 4.68863\n",
      "\n",
      "Iteration: 64\n",
      "RMSE: 4.67631\n",
      "\n",
      "Iteration: 65\n",
      "RMSE: 4.66682\n",
      "\n",
      "Iteration: 66\n",
      "RMSE: 4.65463\n",
      "\n",
      "Iteration: 67\n",
      "RMSE: 4.64508\n",
      "\n",
      "Iteration: 68\n",
      "RMSE: 4.6337\n",
      "\n",
      "Iteration: 69\n",
      "RMSE: 4.62508\n",
      "\n",
      "Iteration: 70\n",
      "RMSE: 4.61585\n",
      "\n",
      "Iteration: 71\n",
      "RMSE: 4.60905\n",
      "\n",
      "Iteration: 72\n",
      "RMSE: 4.6052\n",
      "\n",
      "Iteration: 73\n",
      "RMSE: 4.6026\n",
      "\n",
      "Iteration: 74\n",
      "RMSE: 4.59571\n",
      "\n",
      "Iteration: 75\n",
      "RMSE: 4.591\n",
      "\n",
      "Iteration: 76\n",
      "RMSE: 4.57644\n",
      "\n",
      "Iteration: 77\n",
      "RMSE: 4.56678\n",
      "\n",
      "Iteration: 78\n",
      "RMSE: 4.56103\n",
      "\n",
      "Iteration: 79\n",
      "RMSE: 4.55562\n",
      "\n",
      "Iteration: 80\n",
      "RMSE: 4.5515\n",
      "\n",
      "Iteration: 81\n",
      "RMSE: 4.54187\n",
      "\n",
      "Iteration: 82\n",
      "RMSE: 4.53424\n",
      "\n",
      "Iteration: 83\n",
      "RMSE: 4.52753\n",
      "\n",
      "Iteration: 84\n",
      "RMSE: 4.51906\n",
      "\n",
      "Iteration: 85\n",
      "RMSE: 4.50593\n",
      "\n",
      "Iteration: 86\n",
      "RMSE: 4.50458\n",
      "\n",
      "Iteration: 87\n",
      "RMSE: 4.49481\n",
      "\n",
      "Iteration: 88\n",
      "RMSE: 4.48946\n",
      "\n",
      "Iteration: 89\n",
      "RMSE: 4.48422\n",
      "\n",
      "Iteration: 90\n",
      "RMSE: 4.48155\n",
      "\n",
      "Iteration: 91\n",
      "RMSE: 4.48171\n",
      "\n",
      "Iteration: 92\n",
      "RMSE: 4.47774\n",
      "\n",
      "Iteration: 93\n",
      "RMSE: 4.47049\n",
      "\n",
      "Iteration: 94\n",
      "RMSE: 4.46471\n",
      "\n",
      "Iteration: 95\n",
      "RMSE: 4.45407\n",
      "\n",
      "Iteration: 96\n",
      "RMSE: 4.45284\n",
      "\n",
      "Iteration: 97\n",
      "RMSE: 4.44671\n",
      "\n",
      "Iteration: 98\n",
      "RMSE: 4.44111\n",
      "\n",
      "Iteration: 99\n",
      "RMSE: 4.43353\n",
      "\n",
      "Iteration: 100\n",
      "RMSE: 4.4253\n",
      "\n",
      "Iteration: 101\n",
      "RMSE: 4.42155\n",
      "\n",
      "Iteration: 102\n",
      "RMSE: 4.41482\n",
      "\n",
      "Iteration: 103\n",
      "RMSE: 4.41102\n",
      "\n",
      "Iteration: 104\n",
      "RMSE: 4.40861\n",
      "\n",
      "Iteration: 105\n",
      "RMSE: 4.40511\n",
      "\n",
      "Iteration: 106\n",
      "RMSE: 4.404\n",
      "\n",
      "Iteration: 107\n",
      "RMSE: 4.40011\n",
      "\n",
      "Iteration: 108\n",
      "RMSE: 4.3981\n",
      "\n",
      "Iteration: 109\n",
      "RMSE: 4.39567\n",
      "\n",
      "Iteration: 110\n",
      "RMSE: 4.39007\n",
      "\n",
      "Iteration: 111\n",
      "RMSE: 4.38508\n",
      "\n",
      "Iteration: 112\n",
      "RMSE: 4.37766\n",
      "\n",
      "Iteration: 113\n",
      "RMSE: 4.36911\n",
      "\n",
      "Iteration: 114\n",
      "RMSE: 4.36386\n",
      "\n",
      "Iteration: 115\n",
      "RMSE: 4.36158\n",
      "\n",
      "Iteration: 116\n",
      "RMSE: 4.35696\n",
      "\n",
      "Iteration: 117\n",
      "RMSE: 4.35327\n",
      "\n",
      "Iteration: 118\n",
      "RMSE: 4.34679\n",
      "\n",
      "Iteration: 119\n",
      "RMSE: 4.34363\n",
      "\n",
      "Iteration: 120\n",
      "RMSE: 4.33815\n",
      "\n",
      "Iteration: 121\n",
      "RMSE: 4.33279\n",
      "\n",
      "Iteration: 122\n",
      "RMSE: 4.32862\n",
      "\n",
      "Iteration: 123\n",
      "RMSE: 4.32272\n",
      "\n",
      "Iteration: 124\n",
      "RMSE: 4.31575\n",
      "\n",
      "Iteration: 125\n",
      "RMSE: 4.3088\n",
      "\n",
      "Iteration: 126\n",
      "RMSE: 4.30296\n",
      "\n",
      "Iteration: 127\n",
      "RMSE: 4.3008\n",
      "\n",
      "Iteration: 128\n",
      "RMSE: 4.29517\n",
      "\n",
      "Iteration: 129\n",
      "RMSE: 4.2874\n",
      "\n",
      "Iteration: 130\n",
      "RMSE: 4.28702\n",
      "\n",
      "Iteration: 131\n",
      "RMSE: 4.2855\n",
      "\n",
      "Iteration: 132\n",
      "RMSE: 4.28099\n",
      "\n",
      "Iteration: 133\n",
      "RMSE: 4.2749\n",
      "\n",
      "Iteration: 134\n",
      "RMSE: 4.27634\n",
      "\n",
      "Iteration: 135\n",
      "RMSE: 4.26989\n",
      "\n",
      "Iteration: 136\n",
      "RMSE: 4.27053\n",
      "\n",
      "Iteration: 137\n",
      "RMSE: 4.2677\n",
      "\n",
      "Iteration: 138\n",
      "RMSE: 4.26524\n",
      "\n",
      "Iteration: 139\n",
      "RMSE: 4.26579\n",
      "\n",
      "Iteration: 140\n",
      "RMSE: 4.2608\n",
      "\n",
      "Iteration: 141\n",
      "RMSE: 4.26206\n",
      "\n",
      "Iteration: 142\n",
      "RMSE: 4.25638\n",
      "\n",
      "Iteration: 143\n",
      "RMSE: 4.25494\n",
      "\n",
      "Iteration: 144\n",
      "RMSE: 4.25412\n",
      "\n",
      "Iteration: 145\n",
      "RMSE: 4.25232\n",
      "\n",
      "Iteration: 146\n",
      "RMSE: 4.24726\n",
      "\n",
      "Iteration: 147\n",
      "RMSE: 4.24652\n",
      "\n",
      "Iteration: 148\n",
      "RMSE: 4.24235\n",
      "\n",
      "Iteration: 149\n",
      "RMSE: 4.23943\n",
      "\n",
      "Iteration: 150\n",
      "RMSE: 4.23586\n",
      "\n",
      "Iteration: 151\n",
      "RMSE: 4.23325\n",
      "\n",
      "Iteration: 152\n",
      "RMSE: 4.23221\n",
      "\n",
      "Iteration: 153\n",
      "RMSE: 4.2319\n",
      "\n",
      "Iteration: 154\n",
      "RMSE: 4.22713\n",
      "\n",
      "Iteration: 155\n",
      "RMSE: 4.22729\n",
      "\n",
      "Iteration: 156\n",
      "RMSE: 4.22323\n",
      "\n",
      "Iteration: 157\n",
      "RMSE: 4.21992\n",
      "\n",
      "Iteration: 158\n",
      "RMSE: 4.21569\n",
      "\n",
      "Iteration: 159\n",
      "RMSE: 4.21745\n",
      "\n",
      "Iteration: 160\n",
      "RMSE: 4.21479\n",
      "\n",
      "Iteration: 161\n",
      "RMSE: 4.20791\n",
      "\n",
      "Iteration: 162\n",
      "RMSE: 4.20365\n",
      "\n",
      "Iteration: 163\n",
      "RMSE: 4.20512\n",
      "\n",
      "Iteration: 164\n",
      "RMSE: 4.20221\n",
      "\n",
      "Iteration: 165\n",
      "RMSE: 4.19775\n",
      "\n",
      "Iteration: 166\n",
      "RMSE: 4.19964\n",
      "\n",
      "Iteration: 167\n",
      "RMSE: 4.19683\n",
      "\n",
      "Iteration: 168\n",
      "RMSE: 4.19127\n",
      "\n",
      "Iteration: 169\n",
      "RMSE: 4.18714\n",
      "\n",
      "Iteration: 170\n",
      "RMSE: 4.18431\n",
      "\n",
      "Iteration: 171\n",
      "RMSE: 4.18175\n",
      "\n",
      "Iteration: 172\n",
      "RMSE: 4.18249\n",
      "\n",
      "Iteration: 173\n",
      "RMSE: 4.18414\n",
      "\n",
      "Iteration: 174\n",
      "RMSE: 4.18181\n",
      "\n",
      "Iteration: 175\n",
      "RMSE: 4.18072\n",
      "\n",
      "Iteration: 176\n",
      "RMSE: 4.17982\n",
      "\n",
      "Iteration: 177\n",
      "RMSE: 4.17537\n",
      "\n",
      "Iteration: 178\n",
      "RMSE: 4.17699\n",
      "\n",
      "Iteration: 179\n",
      "RMSE: 4.17467\n",
      "\n",
      "Iteration: 180\n",
      "RMSE: 4.17091\n",
      "\n",
      "Iteration: 181\n",
      "RMSE: 4.16651\n",
      "\n",
      "Iteration: 182\n",
      "RMSE: 4.16448\n",
      "\n",
      "Iteration: 183\n",
      "RMSE: 4.16531\n",
      "\n",
      "Iteration: 184\n",
      "RMSE: 4.16307\n",
      "\n",
      "Iteration: 185\n",
      "RMSE: 4.16212\n",
      "\n",
      "Iteration: 186\n",
      "RMSE: 4.16161\n",
      "\n",
      "Iteration: 187\n",
      "RMSE: 4.16432\n",
      "\n",
      "Iteration: 188\n",
      "RMSE: 4.1601\n",
      "\n",
      "Iteration: 189\n",
      "RMSE: 4.15846\n",
      "\n",
      "Iteration: 190\n",
      "RMSE: 4.15702\n",
      "\n",
      "Iteration: 191\n",
      "RMSE: 4.15735\n",
      "\n",
      "Iteration: 192\n",
      "RMSE: 4.15521\n",
      "\n",
      "Iteration: 193\n",
      "RMSE: 4.15507\n",
      "\n",
      "Iteration: 194\n",
      "RMSE: 4.15309\n",
      "\n",
      "Iteration: 195\n",
      "RMSE: 4.15236\n",
      "\n",
      "Iteration: 196\n",
      "RMSE: 4.15341\n",
      "\n",
      "Iteration: 197\n",
      "RMSE: 4.15087\n",
      "\n",
      "Iteration: 198\n",
      "RMSE: 4.14996\n",
      "\n",
      "Iteration: 199\n",
      "RMSE: 4.14509\n",
      "\n",
      "Iteration: 200\n",
      "RMSE: 4.14444\n",
      "\n",
      "Iteration: 201\n",
      "RMSE: 4.14199\n",
      "\n",
      "Iteration: 202\n",
      "RMSE: 4.14101\n",
      "\n",
      "Iteration: 203\n",
      "RMSE: 4.13956\n",
      "\n",
      "Iteration: 204\n",
      "RMSE: 4.14083\n",
      "\n",
      "Iteration: 205\n",
      "RMSE: 4.13747\n",
      "\n",
      "Iteration: 206\n",
      "RMSE: 4.13314\n",
      "\n",
      "Iteration: 207\n",
      "RMSE: 4.13328\n",
      "\n",
      "Iteration: 208\n",
      "RMSE: 4.13084\n",
      "\n",
      "Iteration: 209\n",
      "RMSE: 4.12983\n",
      "\n",
      "Iteration: 210\n",
      "RMSE: 4.13019\n",
      "\n",
      "Iteration: 211\n",
      "RMSE: 4.12653\n",
      "\n",
      "Iteration: 212\n",
      "RMSE: 4.12689\n",
      "\n",
      "Iteration: 213\n",
      "RMSE: 4.12694\n",
      "\n",
      "Iteration: 214\n",
      "RMSE: 4.12879\n",
      "\n",
      "Iteration: 215\n",
      "RMSE: 4.12763\n",
      "\n",
      "Iteration: 216\n",
      "RMSE: 4.12503\n",
      "\n",
      "Iteration: 217\n",
      "RMSE: 4.12357\n",
      "\n",
      "Iteration: 218\n",
      "RMSE: 4.12456\n",
      "\n",
      "Iteration: 219\n",
      "RMSE: 4.12417\n",
      "\n",
      "Iteration: 220\n",
      "RMSE: 4.11768\n",
      "\n",
      "Iteration: 221\n",
      "RMSE: 4.11751\n",
      "\n",
      "Iteration: 222\n",
      "RMSE: 4.11685\n",
      "\n",
      "Iteration: 223\n",
      "RMSE: 4.11519\n",
      "\n",
      "Iteration: 224\n",
      "RMSE: 4.1137\n",
      "\n",
      "Iteration: 225\n",
      "RMSE: 4.11519\n",
      "\n",
      "Iteration: 226\n",
      "RMSE: 4.11511\n",
      "\n",
      "Iteration: 227\n",
      "RMSE: 4.11472\n",
      "\n",
      "Iteration: 228\n",
      "RMSE: 4.10936\n",
      "\n",
      "Iteration: 229\n",
      "RMSE: 4.10771\n",
      "\n",
      "Iteration: 230\n",
      "RMSE: 4.10801\n",
      "\n",
      "Iteration: 231\n",
      "RMSE: 4.10893\n",
      "\n",
      "Iteration: 232\n",
      "RMSE: 4.10763\n",
      "\n",
      "Iteration: 233\n",
      "RMSE: 4.10631\n",
      "\n",
      "Iteration: 234\n",
      "RMSE: 4.10464\n",
      "\n",
      "Iteration: 235\n",
      "RMSE: 4.10312\n",
      "\n",
      "Iteration: 236\n",
      "RMSE: 4.10098\n",
      "\n",
      "Iteration: 237\n",
      "RMSE: 4.1029\n",
      "\n",
      "Iteration: 238\n",
      "RMSE: 4.10243\n",
      "\n",
      "Iteration: 239\n",
      "RMSE: 4.10198\n",
      "\n",
      "Iteration: 240\n",
      "RMSE: 4.10195\n",
      "\n",
      "Iteration: 241\n",
      "RMSE: 4.10301\n",
      "\n",
      "Iteration: 242\n",
      "RMSE: 4.1047\n",
      "\n",
      "Iteration: 243\n",
      "RMSE: 4.09984\n",
      "\n",
      "Iteration: 244\n",
      "RMSE: 4.10114\n",
      "\n",
      "Iteration: 245\n",
      "RMSE: 4.10002\n",
      "\n",
      "Iteration: 246\n",
      "RMSE: 4.09717\n",
      "\n",
      "Iteration: 247\n",
      "RMSE: 4.09676\n",
      "\n",
      "Iteration: 248\n",
      "RMSE: 4.09634\n",
      "\n",
      "Iteration: 249\n",
      "RMSE: 4.09156\n",
      "\n",
      "Iteration: 250\n",
      "RMSE: 4.08978\n",
      "\n",
      "Iteration: 251\n",
      "RMSE: 4.09043\n",
      "\n",
      "Iteration: 252\n",
      "RMSE: 4.09203\n",
      "\n",
      "Iteration: 253\n",
      "RMSE: 4.089\n",
      "\n",
      "Iteration: 254\n",
      "RMSE: 4.08641\n",
      "\n",
      "Iteration: 255\n",
      "RMSE: 4.08697\n",
      "\n",
      "Iteration: 256\n",
      "RMSE: 4.08632\n",
      "\n",
      "Iteration: 257\n",
      "RMSE: 4.08768\n",
      "\n",
      "Iteration: 258\n",
      "RMSE: 4.08203\n",
      "\n",
      "Iteration: 259\n",
      "RMSE: 4.08772\n",
      "\n",
      "Iteration: 260\n",
      "RMSE: 4.08117\n",
      "\n",
      "Iteration: 261\n",
      "RMSE: 4.07978\n",
      "\n",
      "Iteration: 262\n",
      "RMSE: 4.079\n",
      "\n",
      "Iteration: 263\n",
      "RMSE: 4.07859\n",
      "\n",
      "Iteration: 264\n",
      "RMSE: 4.07441\n",
      "\n",
      "Iteration: 265\n",
      "RMSE: 4.07062\n",
      "\n",
      "Iteration: 266\n",
      "RMSE: 4.07282\n",
      "\n",
      "Iteration: 267\n",
      "RMSE: 4.06806\n",
      "\n",
      "Iteration: 268\n",
      "RMSE: 4.06788\n",
      "\n",
      "Iteration: 269\n",
      "RMSE: 4.07162\n",
      "\n",
      "Iteration: 270\n",
      "RMSE: 4.06768\n",
      "\n",
      "Iteration: 271\n",
      "RMSE: 4.06571\n",
      "\n",
      "Iteration: 272\n",
      "RMSE: 4.06529\n",
      "\n",
      "Iteration: 273\n",
      "RMSE: 4.06396\n",
      "\n",
      "Iteration: 274\n",
      "RMSE: 4.06522\n",
      "\n",
      "Iteration: 275\n",
      "RMSE: 4.06222\n",
      "\n",
      "Iteration: 276\n",
      "RMSE: 4.06297\n",
      "\n",
      "Iteration: 277\n",
      "RMSE: 4.06467\n",
      "\n",
      "Iteration: 278\n",
      "RMSE: 4.06722\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 279\n",
      "RMSE: 4.0684\n",
      "\n",
      "Iteration: 280\n",
      "RMSE: 4.06494\n",
      "\n",
      "Iteration: 281\n",
      "RMSE: 4.06389\n",
      "\n",
      "Iteration: 282\n",
      "RMSE: 4.06309\n",
      "\n",
      "Iteration: 283\n",
      "RMSE: 4.06212\n",
      "\n",
      "Iteration: 284\n",
      "RMSE: 4.06207\n",
      "\n",
      "Iteration: 285\n",
      "RMSE: 4.05934\n",
      "\n",
      "Iteration: 286\n",
      "RMSE: 4.0612\n",
      "\n",
      "Iteration: 287\n",
      "RMSE: 4.05956\n",
      "\n",
      "Iteration: 288\n",
      "RMSE: 4.05898\n",
      "\n",
      "Iteration: 289\n",
      "RMSE: 4.06115\n",
      "\n",
      "Iteration: 290\n",
      "RMSE: 4.06128\n",
      "\n",
      "Iteration: 291\n",
      "RMSE: 4.0611\n",
      "\n",
      "Iteration: 292\n",
      "RMSE: 4.0583\n",
      "\n",
      "Iteration: 293\n",
      "RMSE: 4.06172\n",
      "\n",
      "Iteration: 294\n",
      "RMSE: 4.06312\n",
      "\n",
      "Iteration: 295\n",
      "RMSE: 4.06149\n",
      "\n",
      "Iteration: 296\n",
      "RMSE: 4.06089\n",
      "\n",
      "Iteration: 297\n",
      "RMSE: 4.0614\n",
      "\n",
      "Iteration: 298\n",
      "RMSE: 4.06076\n",
      "\n",
      "Iteration: 299\n",
      "RMSE: 4.05725\n",
      "\n",
      "Iteration: 300\n",
      "RMSE: 4.05363\n",
      "\n",
      "Iteration: 301\n",
      "RMSE: 4.05756\n",
      "\n",
      "Iteration: 302\n",
      "RMSE: 4.05997\n",
      "\n",
      "Iteration: 303\n",
      "RMSE: 4.05964\n",
      "\n",
      "Iteration: 304\n",
      "RMSE: 4.05655\n",
      "\n",
      "Iteration: 305\n",
      "RMSE: 4.05586\n",
      "\n",
      "Iteration: 306\n",
      "RMSE: 4.05818\n",
      "\n",
      "Iteration: 307\n",
      "RMSE: 4.05871\n",
      "\n",
      "Iteration: 308\n",
      "RMSE: 4.05555\n",
      "\n",
      "Iteration: 309\n",
      "RMSE: 4.05488\n",
      "\n",
      "Iteration: 310\n",
      "RMSE: 4.05449\n",
      "\n",
      "Iteration: 311\n",
      "RMSE: 4.05731\n",
      "\n",
      "Iteration: 312\n",
      "RMSE: 4.05424\n",
      "\n",
      "Iteration: 313\n",
      "RMSE: 4.05726\n",
      "\n",
      "Iteration: 314\n",
      "RMSE: 4.05514\n",
      "\n",
      "Iteration: 315\n",
      "RMSE: 4.05924\n",
      "\n",
      "Iteration: 316\n",
      "RMSE: 4.05616\n",
      "\n",
      "Iteration: 317\n",
      "RMSE: 4.05903\n",
      "\n",
      "Iteration: 318\n",
      "RMSE: 4.05738\n",
      "\n",
      "Iteration: 319\n",
      "RMSE: 4.05665\n",
      "\n",
      "Iteration: 320\n",
      "RMSE: 4.05438\n",
      "\n",
      "Iteration: 321\n",
      "RMSE: 4.05673\n",
      "\n",
      "Iteration: 322\n",
      "RMSE: 4.05717\n",
      "\n",
      "Iteration: 323\n",
      "RMSE: 4.05317\n",
      "\n",
      "Iteration: 324\n",
      "RMSE: 4.05329\n",
      "\n",
      "Iteration: 325\n",
      "RMSE: 4.05718\n",
      "\n",
      "Iteration: 326\n",
      "RMSE: 4.05526\n",
      "\n",
      "Iteration: 327\n",
      "RMSE: 4.0578\n",
      "\n",
      "Iteration: 328\n",
      "RMSE: 4.056\n",
      "\n",
      "Iteration: 329\n",
      "RMSE: 4.05501\n",
      "\n",
      "Iteration: 330\n",
      "RMSE: 4.05156\n",
      "\n",
      "Iteration: 331\n",
      "RMSE: 4.05288\n",
      "\n",
      "Iteration: 332\n",
      "RMSE: 4.05339\n",
      "\n",
      "Iteration: 333\n",
      "RMSE: 4.05627\n",
      "\n",
      "Iteration: 334\n",
      "RMSE: 4.05635\n",
      "\n",
      "Iteration: 335\n",
      "RMSE: 4.0532\n",
      "\n",
      "Iteration: 336\n",
      "RMSE: 4.05467\n",
      "\n",
      "Iteration: 337\n",
      "RMSE: 4.04918\n",
      "\n",
      "Iteration: 338\n",
      "RMSE: 4.05194\n",
      "\n",
      "Iteration: 339\n",
      "RMSE: 4.0515\n",
      "\n",
      "Iteration: 340\n",
      "RMSE: 4.05112\n",
      "\n",
      "Iteration: 341\n",
      "RMSE: 4.05337\n",
      "\n",
      "Iteration: 342\n",
      "RMSE: 4.04989\n",
      "\n",
      "Iteration: 343\n",
      "RMSE: 4.04625\n",
      "\n",
      "Iteration: 344\n",
      "RMSE: 4.04658\n",
      "\n",
      "Iteration: 345\n",
      "RMSE: 4.04929\n",
      "\n",
      "Iteration: 346\n",
      "RMSE: 4.04718\n",
      "\n",
      "Iteration: 347\n",
      "RMSE: 4.04987\n",
      "\n",
      "Iteration: 348\n",
      "RMSE: 4.04604\n",
      "\n",
      "Iteration: 349\n",
      "RMSE: 4.0463\n",
      "\n",
      "Iteration: 350\n",
      "RMSE: 4.04668\n",
      "\n",
      "Iteration: 351\n",
      "RMSE: 4.04816\n",
      "\n",
      "Iteration: 352\n",
      "RMSE: 4.04784\n",
      "\n",
      "Iteration: 353\n",
      "RMSE: 4.04726\n",
      "\n",
      "Iteration: 354\n",
      "RMSE: 4.05267\n",
      "\n",
      "Iteration: 355\n",
      "RMSE: 4.04674\n",
      "\n",
      "Iteration: 356\n",
      "RMSE: 4.0483\n",
      "\n",
      "Iteration: 357\n",
      "RMSE: 4.04685\n",
      "\n",
      "Iteration: 358\n",
      "RMSE: 4.05342\n",
      "\n",
      "Iteration: 359\n",
      "RMSE: 4.04822\n",
      "\n",
      "Iteration: 360\n",
      "RMSE: 4.052\n",
      "\n",
      "Iteration: 361\n",
      "RMSE: 4.05\n",
      "\n",
      "Iteration: 362\n",
      "RMSE: 4.05073\n",
      "\n",
      "Iteration: 363\n",
      "RMSE: 4.04697\n",
      "\n",
      "Iteration: 364\n",
      "RMSE: 4.04859\n",
      "\n",
      "Iteration: 365\n",
      "RMSE: 4.04631\n",
      "\n",
      "Iteration: 366\n",
      "RMSE: 4.04836\n",
      "\n",
      "Iteration: 367\n",
      "RMSE: 4.0456\n",
      "\n",
      "Iteration: 368\n",
      "RMSE: 4.04656\n",
      "\n",
      "Iteration: 369\n",
      "RMSE: 4.04852\n",
      "\n",
      "Iteration: 370\n",
      "RMSE: 4.04559\n",
      "\n",
      "Iteration: 371\n",
      "RMSE: 4.04951\n",
      "\n",
      "Iteration: 372\n",
      "RMSE: 4.0491\n",
      "\n",
      "Iteration: 373\n",
      "RMSE: 4.04814\n",
      "\n",
      "Iteration: 374\n",
      "RMSE: 4.04593\n",
      "\n",
      "Iteration: 375\n",
      "RMSE: 4.04409\n",
      "\n",
      "Iteration: 376\n",
      "RMSE: 4.04361\n",
      "\n",
      "Iteration: 377\n",
      "RMSE: 4.04476\n",
      "\n",
      "Iteration: 378\n",
      "RMSE: 4.04576\n",
      "\n",
      "Iteration: 379\n",
      "RMSE: 4.04426\n",
      "\n",
      "Iteration: 380\n",
      "RMSE: 4.04428\n",
      "\n",
      "Iteration: 381\n",
      "RMSE: 4.0454\n",
      "\n",
      "Iteration: 382\n",
      "RMSE: 4.04438\n",
      "\n",
      "Iteration: 383\n",
      "RMSE: 4.04599\n",
      "\n",
      "Iteration: 384\n",
      "RMSE: 4.04047\n",
      "\n",
      "Iteration: 385\n",
      "RMSE: 4.04162\n",
      "\n",
      "Iteration: 386\n",
      "RMSE: 4.04225\n",
      "\n",
      "Iteration: 387\n",
      "RMSE: 4.04026\n",
      "\n",
      "Iteration: 388\n",
      "RMSE: 4.04254\n",
      "\n",
      "Iteration: 389\n",
      "RMSE: 4.04044\n",
      "\n",
      "Iteration: 390\n",
      "RMSE: 4.04225\n",
      "\n",
      "Iteration: 391\n",
      "RMSE: 4.0389\n",
      "\n",
      "Iteration: 392\n",
      "RMSE: 4.03768\n",
      "\n",
      "Iteration: 393\n",
      "RMSE: 4.04319\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xinyuchen/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:36: RuntimeWarning: covariance is not positive-semidefinite.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 394\n",
      "RMSE: 4.04085\n",
      "\n",
      "Iteration: 395\n",
      "RMSE: 4.04268\n",
      "\n",
      "Iteration: 396\n",
      "RMSE: 4.0425\n",
      "\n",
      "Iteration: 397\n",
      "RMSE: 4.04042\n",
      "\n",
      "Iteration: 398\n",
      "RMSE: 4.04092\n",
      "\n",
      "Iteration: 399\n",
      "RMSE: 4.03779\n",
      "\n",
      "Iteration: 400\n",
      "RMSE: 4.04163\n",
      "\n",
      "Iteration: 401\n",
      "RMSE: 4.04327\n",
      "\n",
      "Iteration: 402\n",
      "RMSE: 4.0422\n",
      "\n",
      "Iteration: 403\n",
      "RMSE: 4.04504\n",
      "\n",
      "Iteration: 404\n",
      "RMSE: 4.04549\n",
      "\n",
      "Iteration: 405\n",
      "RMSE: 4.04062\n",
      "\n",
      "Iteration: 406\n",
      "RMSE: 4.03777\n",
      "\n",
      "Iteration: 407\n",
      "RMSE: 4.04032\n",
      "\n",
      "Iteration: 408\n",
      "RMSE: 4.03954\n",
      "\n",
      "Iteration: 409\n",
      "RMSE: 4.04377\n",
      "\n",
      "Iteration: 410\n",
      "RMSE: 4.04143\n",
      "\n",
      "Iteration: 411\n",
      "RMSE: 4.03972\n",
      "\n",
      "Iteration: 412\n",
      "RMSE: 4.04493\n",
      "\n",
      "Iteration: 413\n",
      "RMSE: 4.04041\n",
      "\n",
      "Iteration: 414\n",
      "RMSE: 4.03843\n",
      "\n",
      "Iteration: 415\n",
      "RMSE: 4.03943\n",
      "\n",
      "Iteration: 416\n",
      "RMSE: 4.04237\n",
      "\n",
      "Iteration: 417\n",
      "RMSE: 4.03858\n",
      "\n",
      "Iteration: 418\n",
      "RMSE: 4.03928\n",
      "\n",
      "Iteration: 419\n",
      "RMSE: 4.04381\n",
      "\n",
      "Iteration: 420\n",
      "RMSE: 4.04177\n",
      "\n",
      "Iteration: 421\n",
      "RMSE: 4.03933\n",
      "\n",
      "Iteration: 422\n",
      "RMSE: 4.04199\n",
      "\n",
      "Iteration: 423\n",
      "RMSE: 4.03973\n",
      "\n",
      "Iteration: 424\n",
      "RMSE: 4.04423\n",
      "\n",
      "Iteration: 425\n",
      "RMSE: 4.03968\n",
      "\n",
      "Iteration: 426\n",
      "RMSE: 4.04267\n",
      "\n",
      "Iteration: 427\n",
      "RMSE: 4.04012\n",
      "\n",
      "Iteration: 428\n",
      "RMSE: 4.04209\n",
      "\n",
      "Iteration: 429\n",
      "RMSE: 4.03841\n",
      "\n",
      "Iteration: 430\n",
      "RMSE: 4.03882\n",
      "\n",
      "Iteration: 431\n",
      "RMSE: 4.03768\n",
      "\n",
      "Iteration: 432\n",
      "RMSE: 4.03913\n",
      "\n",
      "Iteration: 433\n",
      "RMSE: 4.03646\n",
      "\n",
      "Iteration: 434\n",
      "RMSE: 4.03684\n",
      "\n",
      "Iteration: 435\n",
      "RMSE: 4.03735\n",
      "\n",
      "Iteration: 436\n",
      "RMSE: 4.03643\n",
      "\n",
      "Iteration: 437\n",
      "RMSE: 4.03717\n",
      "\n",
      "Iteration: 438\n",
      "RMSE: 4.0339\n",
      "\n",
      "Iteration: 439\n",
      "RMSE: 4.03792\n",
      "\n",
      "Iteration: 440\n",
      "RMSE: 4.03692\n",
      "\n",
      "Iteration: 441\n",
      "RMSE: 4.03944\n",
      "\n",
      "Iteration: 442\n",
      "RMSE: 4.04036\n",
      "\n",
      "Iteration: 443\n",
      "RMSE: 4.03861\n",
      "\n",
      "Iteration: 444\n",
      "RMSE: 4.04091\n",
      "\n",
      "Iteration: 445\n",
      "RMSE: 4.03963\n",
      "\n",
      "Iteration: 446\n",
      "RMSE: 4.03945\n",
      "\n",
      "Iteration: 447\n",
      "RMSE: 4.03578\n",
      "\n",
      "Iteration: 448\n",
      "RMSE: 4.03652\n",
      "\n",
      "Iteration: 449\n",
      "RMSE: 4.03756\n",
      "\n",
      "Iteration: 450\n",
      "RMSE: 4.03959\n",
      "\n",
      "Iteration: 451\n",
      "RMSE: 4.03729\n",
      "\n",
      "Iteration: 452\n",
      "RMSE: 4.03663\n",
      "\n",
      "Iteration: 453\n",
      "RMSE: 4.03817\n",
      "\n",
      "Iteration: 454\n",
      "RMSE: 4.04068\n",
      "\n",
      "Iteration: 455\n",
      "RMSE: 4.03919\n",
      "\n",
      "Iteration: 456\n",
      "RMSE: 4.03745\n",
      "\n",
      "Iteration: 457\n",
      "RMSE: 4.03931\n",
      "\n",
      "Iteration: 458\n",
      "RMSE: 4.03754\n",
      "\n",
      "Iteration: 459\n",
      "RMSE: 4.03848\n",
      "\n",
      "Iteration: 460\n",
      "RMSE: 4.03944\n",
      "\n",
      "Iteration: 461\n",
      "RMSE: 4.03829\n",
      "\n",
      "Iteration: 462\n",
      "RMSE: 4.04299\n",
      "\n",
      "Iteration: 463\n",
      "RMSE: 4.04083\n",
      "\n",
      "Iteration: 464\n",
      "RMSE: 4.03713\n",
      "\n",
      "Iteration: 465\n",
      "RMSE: 4.04204\n",
      "\n",
      "Iteration: 466\n",
      "RMSE: 4.03924\n",
      "\n",
      "Iteration: 467\n",
      "RMSE: 4.03674\n",
      "\n",
      "Iteration: 468\n",
      "RMSE: 4.04121\n",
      "\n",
      "Iteration: 469\n",
      "RMSE: 4.03888\n",
      "\n",
      "Iteration: 470\n",
      "RMSE: 4.03983\n",
      "\n",
      "Iteration: 471\n",
      "RMSE: 4.03776\n",
      "\n",
      "Iteration: 472\n",
      "RMSE: 4.04071\n",
      "\n",
      "Iteration: 473\n",
      "RMSE: 4.04284\n",
      "\n",
      "Iteration: 474\n",
      "RMSE: 4.04519\n",
      "\n",
      "Iteration: 475\n",
      "RMSE: 4.04089\n",
      "\n",
      "Iteration: 476\n",
      "RMSE: 4.04054\n",
      "\n",
      "Iteration: 477\n",
      "RMSE: 4.04145\n",
      "\n",
      "Iteration: 478\n",
      "RMSE: 4.03787\n",
      "\n",
      "Iteration: 479\n",
      "RMSE: 4.03813\n",
      "\n",
      "Iteration: 480\n",
      "RMSE: 4.03692\n",
      "\n",
      "Iteration: 481\n",
      "RMSE: 4.04137\n",
      "\n",
      "Iteration: 482\n",
      "RMSE: 4.04116\n",
      "\n",
      "Iteration: 483\n",
      "RMSE: 4.04081\n",
      "\n",
      "Iteration: 484\n",
      "RMSE: 4.03968\n",
      "\n",
      "Iteration: 485\n",
      "RMSE: 4.04026\n",
      "\n",
      "Iteration: 486\n",
      "RMSE: 4.03936\n",
      "\n",
      "Iteration: 487\n",
      "RMSE: 4.03797\n",
      "\n",
      "Iteration: 488\n",
      "RMSE: 4.03718\n",
      "\n",
      "Iteration: 489\n",
      "RMSE: 4.03592\n",
      "\n",
      "Iteration: 490\n",
      "RMSE: 4.03771\n",
      "\n",
      "Iteration: 491\n",
      "RMSE: 4.03816\n",
      "\n",
      "Iteration: 492\n",
      "RMSE: 4.03782\n",
      "\n",
      "Iteration: 493\n",
      "RMSE: 4.04069\n",
      "\n",
      "Iteration: 494\n",
      "RMSE: 4.03547\n",
      "\n",
      "Iteration: 495\n",
      "RMSE: 4.03349\n",
      "\n",
      "Iteration: 496\n",
      "RMSE: 4.03648\n",
      "\n",
      "Iteration: 497\n",
      "RMSE: 4.03858\n",
      "\n",
      "Iteration: 498\n",
      "RMSE: 4.04057\n",
      "\n",
      "Iteration: 499\n",
      "RMSE: 4.0378\n",
      "\n",
      "Iteration: 500\n",
      "RMSE: 4.03612\n",
      "\n",
      "Iteration: 501\n",
      "RMSE: 4.03503\n",
      "\n",
      "Iteration: 502\n",
      "RMSE: 4.03914\n",
      "\n",
      "Iteration: 503\n",
      "RMSE: 4.03587\n",
      "\n",
      "Iteration: 504\n",
      "RMSE: 4.0408\n",
      "\n",
      "Iteration: 505\n",
      "RMSE: 4.03868\n",
      "\n",
      "Iteration: 506\n",
      "RMSE: 4.0414\n",
      "\n",
      "Iteration: 507\n",
      "RMSE: 4.03875\n",
      "\n",
      "Iteration: 508\n",
      "RMSE: 4.03701\n",
      "\n",
      "Iteration: 509\n",
      "RMSE: 4.03803\n",
      "\n",
      "Iteration: 510\n",
      "RMSE: 4.03576\n",
      "\n",
      "Iteration: 511\n",
      "RMSE: 4.03345\n",
      "\n",
      "Iteration: 512\n",
      "RMSE: 4.03612\n",
      "\n",
      "Iteration: 513\n",
      "RMSE: 4.03484\n",
      "\n",
      "Iteration: 514\n",
      "RMSE: 4.03819\n",
      "\n",
      "Iteration: 515\n",
      "RMSE: 4.03638\n",
      "\n",
      "Iteration: 516\n",
      "RMSE: 4.0353\n",
      "\n",
      "Iteration: 517\n",
      "RMSE: 4.02947\n",
      "\n",
      "Iteration: 518\n",
      "RMSE: 4.03592\n",
      "\n",
      "Iteration: 519\n",
      "RMSE: 4.03538\n",
      "\n",
      "Iteration: 520\n",
      "RMSE: 4.0368\n",
      "\n",
      "Iteration: 521\n",
      "RMSE: 4.03988\n",
      "\n",
      "Iteration: 522\n",
      "RMSE: 4.03965\n",
      "\n",
      "Iteration: 523\n",
      "RMSE: 4.03842\n",
      "\n",
      "Iteration: 524\n",
      "RMSE: 4.03902\n",
      "\n",
      "Iteration: 525\n",
      "RMSE: 4.03709\n",
      "\n",
      "Iteration: 526\n",
      "RMSE: 4.03664\n",
      "\n",
      "Iteration: 527\n",
      "RMSE: 4.03763\n",
      "\n",
      "Iteration: 528\n",
      "RMSE: 4.03425\n",
      "\n",
      "Iteration: 529\n",
      "RMSE: 4.03415\n",
      "\n",
      "Iteration: 530\n",
      "RMSE: 4.03088\n",
      "\n",
      "Iteration: 531\n",
      "RMSE: 4.03479\n",
      "\n",
      "Iteration: 532\n",
      "RMSE: 4.03137\n",
      "\n",
      "Iteration: 533\n",
      "RMSE: 4.03254\n",
      "\n",
      "Iteration: 534\n",
      "RMSE: 4.0328\n",
      "\n",
      "Iteration: 535\n",
      "RMSE: 4.03436\n",
      "\n",
      "Iteration: 536\n",
      "RMSE: 4.03596\n",
      "\n",
      "Iteration: 537\n",
      "RMSE: 4.03814\n",
      "\n",
      "Iteration: 538\n",
      "RMSE: 4.03757\n",
      "\n",
      "Iteration: 539\n",
      "RMSE: 4.02783\n",
      "\n",
      "Iteration: 540\n",
      "RMSE: 4.03086\n",
      "\n",
      "Iteration: 541\n",
      "RMSE: 4.03276\n",
      "\n",
      "Iteration: 542\n",
      "RMSE: 4.03118\n",
      "\n",
      "Iteration: 543\n",
      "RMSE: 4.0297\n",
      "\n",
      "Iteration: 544\n",
      "RMSE: 4.03001\n",
      "\n",
      "Iteration: 545\n",
      "RMSE: 4.03049\n",
      "\n",
      "Iteration: 546\n",
      "RMSE: 4.03344\n",
      "\n"
     ]
    },
    {
     "ename": "LinAlgError",
     "evalue": "Matrix is not positive definite",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-e8a1e93d5c2a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmaxiter1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mmaxiter2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mBTMF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdense_mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_lags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxiter1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxiter2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Running time: %d seconds'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-5642926d9e75>\u001b[0m in \u001b[0;36mBTMF\u001b[0;34m(dense_mat, sparse_mat, init, rank, time_lags, maxiter1, maxiter2)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxiter1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_factor_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msparse_mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary_mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtau\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSigma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_var_coefficient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_lags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_factor_x\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msparse_mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary_mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_lags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtau\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSigma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mmat_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-4ff3cab6f23d>\u001b[0m in \u001b[0;36msample_var_coefficient\u001b[0;34m(X, time_lags)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mvar_S\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ_mat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZ_mat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_M\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_Psi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_M\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mSigma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minvwishart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrank\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdim2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_lags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvar_S\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrvs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmat2ten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmnrnd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_M\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_Psi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSigma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSigma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-4ff3cab6f23d>\u001b[0m in \u001b[0;36mmnrnd\u001b[0;34m(M, U, V)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mdim1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mX0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcholesky\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mU\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mQ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcholesky\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mM\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36mcholesky\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m    612\u001b[0m     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_commonType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m     \u001b[0msignature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'D->D'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'd->d'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 614\u001b[0;31m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgufunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    615\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36m_raise_linalgerror_nonposdef\u001b[0;34m(err, flag)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_raise_linalgerror_nonposdef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLinAlgError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Matrix is not positive definite\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_raise_linalgerror_eigenvalues_nonconvergence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLinAlgError\u001b[0m: Matrix is not positive definite"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "dim1, dim2 = sparse_mat.shape\n",
    "rank = 50\n",
    "time_lags = np.array([1, 2, 288])\n",
    "init = {\"W\": 0.1 * np.random.rand(dim1, rank), \"X\": 0.1 * np.random.rand(dim2, rank)}\n",
    "maxiter1 = 1100\n",
    "maxiter2 = 100\n",
    "BTMF(dense_mat, sparse_mat, init, rank, time_lags, maxiter1, maxiter2)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
