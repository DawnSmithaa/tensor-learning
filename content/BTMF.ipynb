{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Temporal Matrix Factorization\n",
    "\n",
    "**Published**: October 8, 2019\n",
    "\n",
    "**Author**: Xinyu Chen [[**GitHub homepage**](https://github.com/xinychen)]\n",
    "\n",
    "**Download**: This Jupyter notebook is at our GitHub repository. If you want to evaluate the code, please download the notebook from the repository of [**tensor-learning**](https://github.com/xinychen/tensor-learning/blob/master/content/BTMF.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract\n",
    "\n",
    "Large-scale and multidimensional spatiotemporal data sets are becoming ubiquitous in many real-world applications such as monitoring traffic and air quality. Making predictions on these time series has become a critical challenge due to not only the large-scale and high-dimensional nature but also the considerable amount of missing data. In this work, we propose a Bayesian Temporal Matrix Factorization (BTMF) model for modeling multidimensional time series - and in particular spatiotemporal data - in the presence of missing data. By integrating low-rank matrix factorization and autoregressive (AR) process into a single probabilistic graphical model, our model can effectively perform predictions without imputing those missing values. We develop efficient Gibbs sampling algorithms for model inference and test the proposed BTMF on several real-world spatiotemporal data sets for both missing data imputation and short-term rolling prediction tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Motivation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Problem Description\n",
    "\n",
    "We assume a spatiotemporal setting for multidimensional time series data throughout this work. In general, modern spatiotemporal data sets collected from sensor networks can be organized as matrix time series. For example, we can denote by matrix $Y\\in\\mathbb{R}^{N\\times T}$ a multivariate time series collected from $N$ locations/sensors on $T$ time stamps, with each row $$\\boldsymbol{y}_{i}=\\left(y_{i,1},y_{i,2},...,y_{i,t-1},y_{i,t},y_{i,t+1},...,y_{i,T}\\right)$$\n",
    "corresponding to the time series collected at location $i$.\n",
    "\n",
    "As mentioned, making accurate predictions on incomplete time series is very challenging, while missing data problem is almost inevitable in real-world applications. Figure 1 illustrates the prediction problem for incomplete time series data. Here we use $(i,t)\\in\\Omega$ to index the observed entries in matrix $Y$.\n",
    "\n",
    "![graphical_matrix_time_series](../images/graphical_matrix_time_series.png)\n",
    "> **Figure 1**: Illustration of multivariate time series and the prediction problem in the presence of missing values (green: observed data; white: missing data; red: prediction).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Model Description\n",
    "\n",
    "Given a partially observed spatiotemporal matrix $Y\\in\\mathbb{R}^{N \\times T}$, one can factorize it into a spatial factor matrix $W\\in\\mathbb{R}^{R \\times N}$ and a temporal factor matrix $X\\in\\mathbb{R}^{R \\times T}$ following general matrix factorization model:\n",
    "$$Y\\approx W^{\\top}X,~~~~(1)$$\n",
    "and element-wise, we have\n",
    "$$y_{it}\\approx \\boldsymbol{w}_{i}^\\top\\boldsymbol{x}_{t}, \\quad \\forall (i,t),~~~~(2)$$\n",
    "where vectors $\\boldsymbol{w}_{i}$ and $\\boldsymbol{x}_{t}$ refer to the $i$-th column of $W$ and the $t$-th column of $X$, respectively.\n",
    "\n",
    "The standard matrix factorization model is a good approach to deal with the missing data problem; however, it cannot capture the dependencies among different columns in $X$, which are critical in modeling time series data. To better characterize the temporal dependencies and impose temporal smoothness, a novel AR regularizer is introduced on $X$ in TRMF ([Yu et al., 2016](https://www.cs.utexas.edu/~rofuyu/papers/tr-mf-nips.pdf)):\n",
    "$$\\begin{array}{l}\\boldsymbol{x}_{t+1}&=\\sum\\nolimits_{k=1}^{d}A_{k}\\boldsymbol{x}_{t+1-h_k}+\\boldsymbol{\\epsilon}_t, \\\\\n",
    "    &=A^\\top \\boldsymbol{v}_{t+1}+\\boldsymbol{\\epsilon}_{t}, \\\\ \\end{array}~~~~(3)$$\n",
    "where $\\mathcal{L}=\\left\\{h_1,\\ldots,h_k,\\ldots,h_d\\right\\}$ is a lag set ($d$ is the order of this AR model), each $A_k$ ($k\\in\\left\\{1,...,d\\right\\}$) is a $R\\times R$ coefficient matrix, and $\\boldsymbol{\\epsilon}_t$ is a zero mean Gaussian noise vector. For brevity, matrix $A\\in \\mathbb{R}^{(R d) \\times R}$ and vector $\\boldsymbol{v}_{t+1}\\in \\mathbb{R}^{(R d) \\times 1}$ are defined as\n",
    "$$A=\\left[A_{1}, \\ldots, A_{d}\\right]^{\\top} ,\\quad \\boldsymbol{v}_{t+1}=\\left[\\begin{array}{c}{\\boldsymbol{x}_{t+1-h_1}} \\\\ {\\vdots} \\\\ {\\boldsymbol{x}_{t+1-h_d}}\\end{array}\\right].$$\n",
    "\n",
    "In [Yu et al., 2016](https://www.cs.utexas.edu/~rofuyu/papers/tr-mf-nips.pdf), to avoid overfitting and reduce the number of parameters, the coefficient matrix in TRMF is further assumed to be a diagonal $A_k=\\text{diag}(\\boldsymbol{\\theta}_{k})$. Therefore, they have\n",
    "$$\\boldsymbol{x}_{t+1}=\\boldsymbol{\\theta}_{1}\\circledast\\boldsymbol{x}_{t+1-h_1}+\\cdots+\\boldsymbol{\\theta}_{d}\\circledast\\boldsymbol{x}_{t+1-h_d}+\\boldsymbol{\\epsilon}_t,~~~~(4)$$\n",
    "where the symbol $\\circledast$ denotes the element-wise Hadamard product. However, unlike Equation (4), a vector autoregressive (VAR) model in Equation (3) is actually more powerful for capturing multivariate time series patterns. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Bayesian Temporal Matrix Factorization with Autoregressive Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
