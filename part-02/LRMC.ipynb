{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Low-Rank Matrix Completion\n",
    "\n",
    "**Published**: September 18, 2019\n",
    "\n",
    "**Author**: Xinyu Chen [[**GitHub homepage**](https://github.com/xinychen)]\n",
    "\n",
    "**Download**: This Jupyter notebook is at our GitHub repository. If you want to evaluate the code, please download the notebook from the repository of [**tensor-learning**](https://github.com/xinychen/tensor-learning/blob/master/part-02/LRMC.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------\n",
    "\n",
    "If you search `matrix completion` as a keyword on [**wiki**](https://en.wikipedia.org/wiki/Matrix_completion), you might see the following explaination for this concept:\n",
    "\n",
    "> Matrix completion is the task of filling in the missing entries of a partially observed matrix. A wide range of datasets are naturally organized in matrix form.\n",
    "\n",
    "From this brief explaination, we could on the one hand see that the matrix completion task requires us to use a mainfold of approaches to impute the missing values for a given matrix which is partially observed. On the other hand, it seems that there are tremendous real-world datasets organized in matrix form, and this means that you have an access to solve real-world missing data problems using matrix completion techniques.\n",
    "\n",
    "**About this chapter**: This chapter does not intend to give a thorough review of low-rank matrix completion, but rather to highlight the basic idea of low-rank matrix completion, and to provide an overview of the key matrix completion techniques that have been successfully used. We direct the interested reader to the more focused references that are provided throughout the chapter.\n",
    "\n",
    "--------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivation: low-rank matrix completion and recovery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main points:\n",
    "\n",
    "- Recommender systems\n",
    "- Image inpainting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommender systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A strong motivation for the matrix completion in recommender systems comes from user ratings of some items like products, movies, or musics which are put into a matrix $\\boldsymbol{X}\\in\\mathbb{R}^{m\\times n}$. The entries $x_{ij},\\forall i\\in\\left\\{1,...,m\\right\\},j\\in\\left\\{1,...,n\\right\\}$ of the matrix correspond to the $i$-th user's rating of item $j$.\n",
    "\n",
    "**A simple example**: In Figure 1, the question is how to predict unobserved entries of the matrix according to the limited observations.\n",
    "\n",
    "![user_ratings_on_movies](../images/user_ratings_on_movies.png)\n",
    "> Figure 1: User ratings of some movies are naturally organized in matrix form, where the matrix has some unobserved entries (i.e., unseen user ratings). Note that this figure is from http://www.princeton.edu/~yc5/ele538b_sparsity/lectures/matrix_recovery.pdf.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image inpainting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the definition on [**wiki**](https://en.wikipedia.org/wiki/Inpainting), inpainting is the process of reconstructing lost or deteriorated parts of images and videos. \n",
    "\n",
    "![lena](../images/lena.bmp)\n",
    "> Figure 2: An image from https://raw.githubusercontent.com/qbzhao/BCPF/master/TestImages/lena.bmp.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem description**: Suppose we observe partial entries of a matrix $\\boldsymbol{Y}\\in\\mathbb{R}^{m\\times n}$, indexed by the set $\\Omega$. Then, the goal is to recover missing (or unobserved) entries in $\\boldsymbol{Y}$.\n",
    "\n",
    "It is not hard to understand the matrix completion problem if you see the following example:\n",
    "\n",
    "> Suppose that we have a matrix like $\\boldsymbol{Y}=\\left[\\begin{array}{ll}{2} & {\\color{red}{?}} \\\\ {\\color{red}{?}} & {4}\\end{array}\\right] \\in \\mathbb{R}^{2 \\times 2}$, which is obviously a partially observed matrix. The observed entries of $\\boldsymbol{Y}$ are indicated by the set $\\Omega=\\left\\{\\color{red}{(1,1),(2,2)}\\right\\}$. Then, applying the matrix completion technique, our final goal is to find a matrix like $\\boldsymbol{X}=\\left[\\begin{array}{ll}{2} & {\\color{red}{8}} \\\\ {\\color{red}{1}} & {4}\\end{array}\\right] \\in \\mathbb{R}^{2 \\times 2}$ that acts as the recovered matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix completion for data without noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ease the reader's journey, there are two steps towards understanding the basic idea of the matrix completion. Indeed, the matrix completion for data without noise give us a notification that the recovered matrix $\\boldsymbol{X}$ has absolutely same entries on $\\Omega$ as the original matrix $\\boldsymbol{Y}$. That is, we have\n",
    "$$\\boldsymbol{X}_{\\Omega}=\\boldsymbol{Y}_{\\Omega}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noisy matrix completion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
